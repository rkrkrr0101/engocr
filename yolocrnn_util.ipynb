{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "import cv2\n",
    "import copy\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imagecreate(imgpath,gray=False):\n",
    "    imgw=320\n",
    "    imgh=320\n",
    "    if gray==False:\n",
    "        img=cv2.imread(imgpath)\n",
    "    else:\n",
    "        img=cv2.imread(imgpath,cv2.IMREAD_GRAYSCALE)\n",
    "    img=img.astype(np.float32)\n",
    "    img=cv2.resize(img,(imgw,imgh))\n",
    "\n",
    "    cv2.imwrite('abc.jpg',img)\n",
    "    img=img/255.0\n",
    "    return img\n",
    "def yoloimagecreate(imgpath):\n",
    "\n",
    "    img=imagecreate(imgpath)\n",
    "    img=np.expand_dims(img,0)\n",
    "    return img\n",
    "#yolo랑 crnn이랑 묶어서만들어도 될거같긴한데 귀찮아..\n",
    "#귀찮지만했다..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolopostprocess(features,threshold=0.0):\n",
    "    def sigmoid(x,threshold=0.0):\n",
    "        return (1./(1.+np.exp(-x)))+threshold\n",
    "    #교체할일있을때 앵커랑 앵커마스크,클래스수 하드코딩말고 밖으로 빼는거도 생각\n",
    "    num_classes=1\n",
    "    sigmoid = np.vectorize(sigmoid)\n",
    "    proto_box=[]\n",
    "    proto_scores=[]\n",
    "    for idx, val in enumerate(features):\n",
    "        #교체할일있을때 앵커랑 앵커마스크,클래스수 하드코딩말고 밖으로 빼는거도 생각\n",
    "        anchors = np.array([np.array([10,13]), np.array([16,30]), np.array([33,23]), np.array([30,61]), np.array([62,45]), np.array([59,119]), np.array([116,90]), np.array([156,198]), np.array([373,326])])\n",
    "        anchor_mask = [[6,7,8], [3,4,5], [0,1,2]]\n",
    "        input_shape = np.asarray(np.shape(features[0])[1 : 3]) * 32\n",
    "        first = anchors[anchor_mask[idx]]\n",
    "        image_size = (320, 320)\n",
    "        num_anchors = len(first)\n",
    "        anchors_tensor = np.reshape(first, [1, 1, 1, num_anchors, 2])\n",
    "        grid_shape = np.shape(val)[1 : 3]\n",
    "        b = np.reshape(np.arange(0, stop=grid_shape[0]), [-1, 1, 1, 1])\n",
    "        grid_y = np.tile(np.reshape(np.arange(0, stop=grid_shape[0]), [-1, 1, 1, 1]), [1, grid_shape[1], 1, 1])\n",
    "        grid_x = np.tile(np.reshape(np.arange(0, stop=grid_shape[1]), [1, -1, 1, 1]),\n",
    "                        [grid_shape[0], 1, 1, 1])\n",
    "        grid = np.concatenate([grid_x, grid_y], axis=3)\n",
    "        feats = np.reshape(\n",
    "                val, [-1, grid_shape[0], grid_shape[1], num_anchors, num_classes + 5])\n",
    "\n",
    "        box_xy = (sigmoid(feats[..., :2],threshold) + grid) / grid_shape[::-1]\n",
    "        pre_box_wh = feats[..., 2:4] * anchors_tensor / input_shape[::-1]\n",
    "        box_wh = np.exp(feats[..., 2:4]) * anchors_tensor / input_shape[::-1]\n",
    "        box_confidence = sigmoid(feats[..., 4:5],threshold)\n",
    "        box_class_probs = sigmoid(feats[..., 5:],threshold)\n",
    "\n",
    "        box_yx = box_xy[..., ::-1]\n",
    "        box_hw = box_wh[..., ::-1]\n",
    "        image_shape = np.array([320, 320])\n",
    "        new_shape = np.round((image_shape * np.min(input_shape/image_shape)))\n",
    "        offset = (input_shape-new_shape)/2./input_shape\n",
    "        scale = input_shape/new_shape\n",
    "        box_yx = (box_yx - offset) #* scale\n",
    "        #box_hw *= scale\n",
    "        #box_hw*=1.0\n",
    "\n",
    "        box_mins = box_yx - (box_hw / 2.)\n",
    "        box_maxes = box_yx + (box_hw / 2.)\n",
    "\n",
    "        boxes = np.concatenate([\n",
    "                box_mins[..., 0:1],  # y_min\n",
    "                box_mins[..., 1:2],  # x_min\n",
    "                box_maxes[..., 0:1],  # y_max\n",
    "                box_maxes[..., 1:2]  # x_max\n",
    "            ], axis=4)\n",
    "\n",
    "        # Scale boxes back to original image shape.\n",
    "        scaler = np.concatenate([image_shape, image_shape])\n",
    "        boxes *= scaler\n",
    "        #here at original implementation is loosing of data, because batch size is ignored\n",
    "        boxes = np.reshape(boxes, [boxes.shape[0], -1, 4])\n",
    "        box_scores = box_confidence * box_class_probs\n",
    "        box_scores = np.reshape(box_scores, [box_scores.shape[0], -1, num_classes])\n",
    "        proto_box.append(boxes)\n",
    "        proto_scores.append(box_scores)\n",
    "    proto_box = np.concatenate(proto_box, axis=1)\n",
    "    proto_scores = np.concatenate(proto_scores, axis=1)\n",
    "    mask = proto_scores >= 0.6\n",
    "    _boxes = []\n",
    "    #yolo모델후처리(함수로빼자)    \n",
    "    for idx, batch in enumerate(proto_scores):\n",
    "        final_classes = []\n",
    "        final_boxes = []\n",
    "        final_scores = []\n",
    "        for c in range(num_classes):\n",
    "            class_boxes = proto_box[idx, mask[idx, :, c]]\n",
    "            class_box_scores = proto_scores[idx, :, c][mask[idx, :, c]]\n",
    "            classes = np.ones_like(class_box_scores, dtype=\"int32\") * c\n",
    "            final_boxes.append(class_boxes)\n",
    "            final_scores.append(class_box_scores)\n",
    "        final_boxes = np.concatenate(final_boxes, axis=0)\n",
    "        final_scores = np.concatenate(final_scores, axis=0)\n",
    "        _boxes.append(final_boxes)\n",
    "    #yolo모델후처리(함수로빼자 위랑묶어서)\n",
    "    #묶기완료\n",
    "    return final_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crnnpredict(model,imgpath,boxes):\n",
    "    img=imagecreate(imgpath,gray=True)\n",
    "    outputdata=[]\n",
    "    for cropbox in boxes:\n",
    "        cropped_img = copy.deepcopy(img[int(cropbox[0]):  int(cropbox[2]),int(cropbox[1]): int(cropbox[3])])\n",
    "        cropped_img=cv2.resize(cropped_img,(256,32))\n",
    "        cropped_img=cropped_img.astype(np.float32)        \n",
    "        cropped_img=cropped_img.T\n",
    "        cropped_img=np.expand_dims(cropped_img,axis=-1)\n",
    "        cropped_img=np.expand_dims(cropped_img,axis=0)\n",
    "        outputdata.append (model.predict(cropped_img))\n",
    "    return outputdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labels_to_text(labels):     \n",
    "    alphabet = \"abcdefghijklmnopqrstuvwxyz0123456789\"\n",
    "    alphabet87 = string.ascii_lowercase + string.ascii_uppercase + string.digits + ' +-*.,:!?%&$~/()[]<>\"\\'@#_'\n",
    "    return ''.join(list(map(lambda x: alphabet87[int(x)], labels)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postcrnn(outputdata):\n",
    "    rtrlabel=[]\n",
    "    for i,out in enumerate( outputdata):\n",
    "        res=[]\n",
    "        for data in out[0]:\n",
    "            listdata=list(data)\n",
    "            res.append( listdata.index(max(listdata)))\n",
    "\n",
    "        resu=[]\n",
    "        for i,abc in enumerate(res) :\n",
    "            if abc!=86:\n",
    "                resu.append(abc)\n",
    "        rtrlabel.append(labels_to_text(resu))\n",
    "    return rtrlabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
