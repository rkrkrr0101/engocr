{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Activation,BatchNormalization,Lambda,Input,Conv2D,Bidirectional,LSTM, Concatenate, MaxPooling2D,GlobalAveragePooling2D\n",
    "import tensorflow.keras.backend as K\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from time import time\n",
    "import datetime\n",
    "import numpy as np\n",
    "from generater import crnnGenerator\n",
    "import logging\n",
    "logger=tf.get_logger()\n",
    "logger.setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 30, 31, 29]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def convert_to_onehot(data):\n",
    "    #Creates a dict, that maps to every char of alphabet an unique int based on position\n",
    "    alphabet = \"abcdefghijklmnopqrstuvwxyz0123456789\"\n",
    "    char_to_int = dict((c,i) for i,c in enumerate(alphabet))\n",
    "    \n",
    "    encoded_data = []\n",
    "    #Replaces every char in data with the mapped int\n",
    "    encoded_data.append([char_to_int[char] for char in data])\n",
    "    \n",
    "    \n",
    "\n",
    "    #This part now replaces the int by an one-hot array with size alphabet\n",
    "    one_hot = []\n",
    "    for value in encoded_data:\n",
    "        #At first, the whole array is initialized with 0\n",
    "        \n",
    "        for indexvalue in value:\n",
    "            letter = [0 for _ in range(len(alphabet))]\n",
    "            #Only at the number of the int, 1 is written\n",
    "\n",
    "            letter[indexvalue] = 1\n",
    "            \n",
    "            one_hot.append(letter)\n",
    "    return one_hot\n",
    "\n",
    "def convert_to_lable(data):\n",
    "    alphabet = \"abcdefghijklmnopqrstuvwxyz0123456789\"\n",
    "    return list(map(lambda x: alphabet.index(x), data))\n",
    "\n",
    "\n",
    "\n",
    "convert_to_lable('abcd453')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def crnn():\n",
    "    x=image_input=Input(name='image_input',shape=[128,64,1],dtype='float32')\n",
    "    \"\"\"\n",
    "    minx=Input(name='minx',shape=[1],dtype='float32')\n",
    "    miny=Input(name='miny',shape=[1],dtype='float32')\n",
    "    maxx=Input(name='maxx',shape=[1],dtype='float32')\n",
    "    maxy=Input(name='maxy',shape=[1],dtype='float32')\n",
    "    def cropimage(img,minx=0,miny=0,maxx=0,maxy=0):\n",
    "        \n",
    "        return tf.image.crop_to_bounding_box(img,minx,miny,maxx-minx,maxy-miny)\n",
    "    x=Lambda(cropimage)([x,minx,miny,maxx,maxy])\n",
    "    \n",
    "    \"\"\"\n",
    "        \n",
    "    x=Conv2D(64, (3, 3), strides=(1, 1), activation='relu', padding='same', name='conv1_1')(x)\n",
    "    x=MaxPooling2D(pool_size=(2, 2), name='pool1', padding='same')(x)#64 32\n",
    "    \n",
    "    x=Conv2D(128, (3, 3), strides=(1, 1), activation='relu', padding='same', name='conv2_1')(x)\n",
    "    #x=MaxPooling2D(pool_size=(2, 2), strides=(2, 2), name='pool2', padding='same')(x)# 32 16\n",
    "\n",
    "    x=Conv2D(256, (3, 3), strides=(1, 1), activation='relu', padding='same', name='conv3_1')(x)\n",
    "    x=Conv2D(256, (3, 3), strides=(1, 1), activation='relu', padding='same', name='conv3_2')(x)\n",
    "    #x=MaxPooling2D(pool_size=(2, 2), strides=(2, 2), name='pool3', padding='same')(x)# 16 8\n",
    "    \n",
    "    x=Conv2D(512, (3, 3), strides=(1, 1), activation='relu', padding='same', name='conv4_1')(x)\n",
    "    x=BatchNormalization(name='batch1')(x)\n",
    "    \n",
    "    x=Conv2D(512, (3, 3), strides=(1, 1), activation='relu', padding='same', name='conv5_1')(x)\n",
    "    \n",
    "    x=BatchNormalization(name='batch2')(x)\n",
    "    #x=MaxPooling2D(pool_size=(2, 2), strides=(1, 2), name='pool5', padding='valid')(x)# 8 4\n",
    "    #63 31 512\n",
    "    x=aa=Conv2D(512, (2, 2), strides=(1, 1), activation='relu', padding='valid', name='conv6_1')(x)#63 31 512\n",
    "    x=keras.layers.Reshape((-1,512))(x)\n",
    "    print(aa)\n",
    "    x=Bidirectional(LSTM(256, return_sequences=True))(x)\n",
    "    x=Bidirectional(LSTM(256, return_sequences=True))(x)\n",
    "    \n",
    "    num_classes=36+1\n",
    "    x=keras.layers.Dense(num_classes, name='dense1')(x)#알파벳+숫자#1953 36\n",
    "    \n",
    "    x=y_pred= Activation('softmax', name='softmax')(x)#1953 36\n",
    "    \n",
    "   # model_pred=keras.models.Model(inputs=[image_input,minx,miny,maxx,maxy],outputs=x)\n",
    "    model_pred=keras.models.Model(inputs=image_input,outputs=x)\n",
    "    \n",
    "    #maxstringlen=int(y_pred.shape[1])\n",
    "    maxstringlen=100\n",
    "    \n",
    "    def ctc_lambda_func(args):\n",
    "        y_pred,labels, input_length, label_length = args\n",
    "          #y_pred = y_pred[:, 2:, :] \n",
    "        return K.ctc_batch_cost(y_true=labels,y_pred=y_pred,input_length=input_length,label_length=label_length)    \n",
    "        #return tf.nn.ctc_loss(labels=labels,logits=y_pred,logit_length=input_length,label_length=label_length,logits_time_major=False)    \n",
    "    \n",
    "    labels = Input(name='labels', shape=[maxstringlen], dtype='float32')\n",
    "    input_length = Input(name='input_length', shape=[1], dtype='int64')\n",
    "    label_length = Input(name='label_length', shape=[1], dtype='int64') \n",
    "    \n",
    "    ctcloss=Lambda(ctc_lambda_func,output_shape=(1,),name='ctcloss')([y_pred,labels,input_length,label_length])\n",
    "    \n",
    "   # model_train=keras.models.Model(inputs=[image_input,minx,miny,maxx,maxy,labels,input_length,label_length],outputs=ctc_loss)\n",
    "    model_train=keras.models.Model(inputs=[image_input,labels,input_length,label_length],outputs=ctcloss)\n",
    "    \n",
    "    return model_train,model_pred,maxstringlen\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KerasTensor(type_spec=TensorSpec(shape=(None, 63, 31, 512), dtype=tf.float32, name=None), name='conv6_1/Relu:0', description=\"created by layer 'conv6_1'\")\n"
     ]
    }
   ],
   "source": [
    "traincrnn,predcrnn,inputlength=crnn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainstart\n",
      "valstart\n",
      "valend\n"
     ]
    }
   ],
   "source": [
    "cropvalpath='D:/ocr/croptestimage/'\n",
    "croptrainpath='D:/ocr/croptestvalimage/'\n",
    "cropvaljson='D:/ocr/valcrnn.json'\n",
    "batch=32\n",
    "traingen=crnnGenerator(imgpath=croptrainpath,labelpath=cropvaljson,imgw=128,imgh=64,batch_size=batch,\n",
    "                      maxlen=inputlength,inputlen=inputlength)\n",
    "print('trainstart')\n",
    "traingen.build_data()\n",
    "print('valstart')\n",
    "valgen=crnnGenerator(imgpath=cropvalpath,labelpath=cropvaljson,imgw=128,imgh=64,batch_size=batch,\n",
    "                      maxlen=inputlength,inputlen=inputlength)\n",
    "valgen.build_data()\n",
    "print('valend')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "import winsound as sd\n",
    "\n",
    "def beepsound():\n",
    "    fr = 2000    # range : 37 ~ 32767\n",
    "    du = 1000     # 1000 ms ==1second\n",
    "    sd.Beep(fr, du) # winsound.Beep(frequency, duration)\n",
    "beepsound()\n",
    "\"\"\"\n",
    "inputlength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "traincrnn.compile(optimizer='adam',loss={'ctcloss':lambda labels,y_pred:y_pred})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.callbacks import TensorBoard  ## TensorBoard 를 import합니다.\n",
    "modelver='crnn_train_v1'\n",
    "checkdir = './checkpoints/' + datetime.datetime.now().strftime('%Y%m%d%H%M') + '_' + modelver\n",
    "if not os.path.exists(checkdir):\n",
    "    os.makedirs(checkdir)\n",
    "\n",
    "with open(checkdir+'/source.py','wb') as f:\n",
    "    source = ''.join(['# In[%i]\\n%s\\n\\n' % (i, In[i]) for i in range(len(In))])\n",
    "    f.write(source.encode())\n",
    "log_dir = \"./logs/fit/\"+ datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard =TensorBoard(log_dir=log_dir,histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "451/451 [==============================] - 695s 2s/step - loss: 17.0959 - val_loss: 16.3440\n",
      "\n",
      "Epoch 00001: saving model to ./checkpoints/202107180819_crnn_train_v1\\weights.001.h5\n",
      "Epoch 2/10\n",
      "451/451 [==============================] - 678s 2s/step - loss: 15.8698 - val_loss: 15.7036\n",
      "\n",
      "Epoch 00002: saving model to ./checkpoints/202107180819_crnn_train_v1\\weights.002.h5\n",
      "Epoch 3/10\n",
      "451/451 [==============================] - 681s 2s/step - loss: 15.5599 - val_loss: 15.7733\n",
      "\n",
      "Epoch 00003: saving model to ./checkpoints/202107180819_crnn_train_v1\\weights.003.h5\n",
      "Epoch 4/10\n",
      "451/451 [==============================] - 681s 2s/step - loss: 15.2168 - val_loss: 15.3377\n",
      "\n",
      "Epoch 00004: saving model to ./checkpoints/202107180819_crnn_train_v1\\weights.004.h5\n",
      "Epoch 5/10\n",
      "451/451 [==============================] - 680s 2s/step - loss: 15.0364 - val_loss: 14.9878\n",
      "\n",
      "Epoch 00005: saving model to ./checkpoints/202107180819_crnn_train_v1\\weights.005.h5\n",
      "Epoch 6/10\n",
      "451/451 [==============================] - 683s 2s/step - loss: 14.9257 - val_loss: 15.0749\n",
      "\n",
      "Epoch 00006: saving model to ./checkpoints/202107180819_crnn_train_v1\\weights.006.h5\n",
      "Epoch 7/10\n",
      "451/451 [==============================] - 693s 2s/step - loss: 14.8622 - val_loss: 15.5097\n",
      "\n",
      "Epoch 00007: saving model to ./checkpoints/202107180819_crnn_train_v1\\weights.007.h5\n",
      "Epoch 8/10\n",
      "451/451 [==============================] - 693s 2s/step - loss: 14.8347 - val_loss: 14.9503\n",
      "\n",
      "Epoch 00008: saving model to ./checkpoints/202107180819_crnn_train_v1\\weights.008.h5\n",
      "Epoch 9/10\n",
      "451/451 [==============================] - 686s 2s/step - loss: 14.7318 - val_loss: 14.9445\n",
      "\n",
      "Epoch 00009: saving model to ./checkpoints/202107180819_crnn_train_v1\\weights.009.h5\n",
      "Epoch 10/10\n",
      "451/451 [==============================] - 693s 2s/step - loss: 14.7138 - val_loss: 15.0556\n",
      "\n",
      "Epoch 00010: saving model to ./checkpoints/202107180819_crnn_train_v1\\weights.010.h5\n"
     ]
    }
   ],
   "source": [
    "#[image_input,labels,input_length,label_length]\n",
    "\"\"\"\n",
    "his=traincrnn.fit(x=[valdata,valdata.labels,np.array( inputlengthlist),np.array(vallabellength)],\n",
    "              y=valdata.labels,\n",
    "                batch_size=16, \n",
    "              epochs=15,\n",
    "              callbacks=[keras.callbacks.ModelCheckpoint(checkdir+'/weights.{epoch:03d}.h5', verbose=1, save_weights_only=True),\n",
    "                         tensorboard]\n",
    "             )\n",
    "\"\"\"\n",
    "his=traincrnn.fit_generator(generator=traingen.next_batch(),\n",
    "                            steps_per_epoch=int(traingen.imgcount/batch),\n",
    "                            epochs=10,\n",
    "                            callbacks=[keras.callbacks.ModelCheckpoint(checkdir+'/weights.{epoch:03d}.h5', verbose=1, moniter='loss'),\n",
    "                            tensorboard],\n",
    "                            validation_data=valgen.next_batch(),\n",
    "                            validation_steps=int(valgen.imgcount/batch)\n",
    "                            \n",
    "                           \n",
    "                           \n",
    "                           )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[ 54.         53.         48.       ]\n",
      "   [ 54.         53.         48.       ]\n",
      "   [ 54.         53.         48.       ]\n",
      "   ...\n",
      "   [ 78.        100.         28.       ]\n",
      "   [ 78.        100.         28.       ]\n",
      "   [ 78.        100.         28.       ]]\n",
      "\n",
      "  [[ 54.         53.         48.       ]\n",
      "   [ 54.         53.         48.       ]\n",
      "   [ 54.         53.         48.       ]\n",
      "   ...\n",
      "   [ 78.        100.         28.       ]\n",
      "   [ 78.        100.         28.       ]\n",
      "   [ 78.        100.         28.       ]]\n",
      "\n",
      "  [[ 54.         53.         48.       ]\n",
      "   [ 54.         53.         48.       ]\n",
      "   [ 54.         53.         48.       ]\n",
      "   ...\n",
      "   [ 78.        100.         28.       ]\n",
      "   [ 78.        100.         28.       ]\n",
      "   [ 78.        100.         28.       ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 30.         30.         42.       ]\n",
      "   [ 30.         30.         42.       ]\n",
      "   [ 30.         30.         42.       ]\n",
      "   ...\n",
      "   [ 63.         62.         42.       ]\n",
      "   [ 63.         62.         42.       ]\n",
      "   [ 63.         62.         42.       ]]\n",
      "\n",
      "  [[ 30.         30.         42.       ]\n",
      "   [ 30.         30.         42.       ]\n",
      "   [ 30.         30.         42.       ]\n",
      "   ...\n",
      "   [ 63.         62.         42.       ]\n",
      "   [ 63.         62.         42.       ]\n",
      "   [ 63.         62.         42.       ]]\n",
      "\n",
      "  [[ 30.         30.         42.       ]\n",
      "   [ 30.         30.         42.       ]\n",
      "   [ 30.         30.         42.       ]\n",
      "   ...\n",
      "   [ 63.         62.         42.       ]\n",
      "   [ 63.         62.         42.       ]\n",
      "   [ 63.         62.         42.       ]]]\n",
      "\n",
      "\n",
      " [[[238.        238.        238.       ]\n",
      "   [238.5       238.5       238.5      ]\n",
      "   [239.        239.        239.       ]\n",
      "   ...\n",
      "   [238.16666   238.16666   238.16666  ]\n",
      "   [237.        237.        237.       ]\n",
      "   [236.        236.        236.       ]]\n",
      "\n",
      "  [[238.        238.        238.       ]\n",
      "   [238.5       238.5       238.5      ]\n",
      "   [239.        239.        239.       ]\n",
      "   ...\n",
      "   [238.16666   238.16666   238.16666  ]\n",
      "   [237.75      237.75      237.75     ]\n",
      "   [237.5       237.5       237.5      ]]\n",
      "\n",
      "  [[238.        238.        238.       ]\n",
      "   [238.41667   238.41667   238.41667  ]\n",
      "   [238.83333   238.83333   238.83333  ]\n",
      "   ...\n",
      "   [238.16666   238.16666   238.16666  ]\n",
      "   [238.58333   238.58333   238.58333  ]\n",
      "   [239.16667   239.16667   239.16667  ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[243.        243.        243.       ]\n",
      "   [242.5       242.5       242.5      ]\n",
      "   [241.83333   241.83333   241.83333  ]\n",
      "   ...\n",
      "   [238.16666   238.16666   238.16666  ]\n",
      "   [239.        239.        239.       ]\n",
      "   [240.        240.        240.       ]]\n",
      "\n",
      "  [[242.5       242.5       242.5      ]\n",
      "   [242.25      242.25      242.25     ]\n",
      "   [241.91666   241.91666   241.91666  ]\n",
      "   ...\n",
      "   [238.16666   238.16666   238.16666  ]\n",
      "   [239.        239.        239.       ]\n",
      "   [240.        240.        240.       ]]\n",
      "\n",
      "  [[242.        242.        242.       ]\n",
      "   [242.        242.        242.       ]\n",
      "   [242.        242.        242.       ]\n",
      "   ...\n",
      "   [238.16666   238.16666   238.16666  ]\n",
      "   [239.        239.        239.       ]\n",
      "   [240.        240.        240.       ]]]\n",
      "\n",
      "\n",
      " [[[255.        253.        250.       ]\n",
      "   [255.        253.        250.       ]\n",
      "   [255.        253.        250.       ]\n",
      "   ...\n",
      "   [246.        246.        246.       ]\n",
      "   [246.        246.        246.       ]\n",
      "   [246.        246.        246.       ]]\n",
      "\n",
      "  [[255.        253.        250.       ]\n",
      "   [255.        253.        250.       ]\n",
      "   [255.        253.        250.       ]\n",
      "   ...\n",
      "   [246.        246.        246.       ]\n",
      "   [246.        246.        246.       ]\n",
      "   [246.        246.        246.       ]]\n",
      "\n",
      "  [[255.        253.        250.       ]\n",
      "   [255.        253.        250.       ]\n",
      "   [255.        253.        250.       ]\n",
      "   ...\n",
      "   [246.        246.        246.       ]\n",
      "   [246.        246.        246.       ]\n",
      "   [246.        246.        246.       ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[240.        251.        253.       ]\n",
      "   [240.        251.        253.       ]\n",
      "   [240.        251.        253.       ]\n",
      "   ...\n",
      "   [244.        255.        255.       ]\n",
      "   [244.        255.        255.       ]\n",
      "   [244.        255.        255.       ]]\n",
      "\n",
      "  [[240.        251.        253.       ]\n",
      "   [240.        251.        253.       ]\n",
      "   [240.        251.        253.       ]\n",
      "   ...\n",
      "   [244.        255.        255.       ]\n",
      "   [244.        255.        255.       ]\n",
      "   [244.        255.        255.       ]]\n",
      "\n",
      "  [[240.        251.        253.       ]\n",
      "   [240.        251.        253.       ]\n",
      "   [240.        251.        253.       ]\n",
      "   ...\n",
      "   [244.        255.        255.       ]\n",
      "   [244.        255.        255.       ]\n",
      "   [244.        255.        255.       ]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[ 18.         22.         70.       ]\n",
      "   [ 18.         22.         70.       ]\n",
      "   [ 17.983334   21.983334   69.98333  ]\n",
      "   ...\n",
      "   [ 14.016666   25.033333   69.98334  ]\n",
      "   [ 14.         25.         70.       ]\n",
      "   [ 14.         25.         70.       ]]\n",
      "\n",
      "  [[ 18.         22.         70.       ]\n",
      "   [ 18.         22.         70.       ]\n",
      "   [ 17.983334   21.983334   69.98333  ]\n",
      "   ...\n",
      "   [ 14.016666   25.033333   69.98334  ]\n",
      "   [ 14.         25.         70.       ]\n",
      "   [ 14.         25.         70.       ]]\n",
      "\n",
      "  [[ 17.966667   21.966667   69.95     ]\n",
      "   [ 17.966667   21.966667   69.95     ]\n",
      "   [ 17.95       21.95       69.93333  ]\n",
      "   ...\n",
      "   [ 14.         25.033054   69.93389  ]\n",
      "   [ 13.983334   25.         69.95     ]\n",
      "   [ 13.983334   25.         69.95     ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[  3.0499992  16.05       61.05     ]\n",
      "   [  3.0499992  16.05       61.05     ]\n",
      "   [  3.0499992  16.05       61.05     ]\n",
      "   ...\n",
      "   [ 13.033055   24.999722   74.983055 ]\n",
      "   [ 12.983334   24.983334   74.95     ]\n",
      "   [ 12.983334   24.983334   74.95     ]]\n",
      "\n",
      "  [[  3.         16.         61.       ]\n",
      "   [  3.         16.         61.       ]\n",
      "   [  3.         16.         61.       ]\n",
      "   ...\n",
      "   [ 13.049999   25.016666   75.03333  ]\n",
      "   [ 13.         25.         75.       ]\n",
      "   [ 13.         25.         75.       ]]\n",
      "\n",
      "  [[  3.         16.         61.       ]\n",
      "   [  3.         16.         61.       ]\n",
      "   [  3.         16.         61.       ]\n",
      "   ...\n",
      "   [ 13.049999   25.016666   75.03333  ]\n",
      "   [ 13.         25.         75.       ]\n",
      "   [ 13.         25.         75.       ]]]\n",
      "\n",
      "\n",
      " [[[106.         94.        134.       ]\n",
      "   [106.         94.        134.       ]\n",
      "   [106.         94.        134.       ]\n",
      "   ...\n",
      "   [255.        245.        253.       ]\n",
      "   [255.        245.        253.       ]\n",
      "   [255.        245.        253.       ]]\n",
      "\n",
      "  [[106.         94.        134.       ]\n",
      "   [106.         94.        134.       ]\n",
      "   [106.         94.        134.       ]\n",
      "   ...\n",
      "   [255.        245.        253.       ]\n",
      "   [255.        245.        253.       ]\n",
      "   [255.        245.        253.       ]]\n",
      "\n",
      "  [[106.         94.        134.       ]\n",
      "   [106.         94.        134.       ]\n",
      "   [106.         94.        134.       ]\n",
      "   ...\n",
      "   [255.        245.        253.       ]\n",
      "   [255.        245.        253.       ]\n",
      "   [255.        245.        253.       ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[148.        146.        195.       ]\n",
      "   [148.        146.        195.       ]\n",
      "   [148.        146.        195.       ]\n",
      "   ...\n",
      "   [185.        201.        224.       ]\n",
      "   [185.        201.        224.       ]\n",
      "   [185.        201.        224.       ]]\n",
      "\n",
      "  [[148.        146.        195.       ]\n",
      "   [148.        146.        195.       ]\n",
      "   [148.        146.        195.       ]\n",
      "   ...\n",
      "   [185.        201.        224.       ]\n",
      "   [185.        201.        224.       ]\n",
      "   [185.        201.        224.       ]]\n",
      "\n",
      "  [[148.        146.        195.       ]\n",
      "   [148.        146.        195.       ]\n",
      "   [148.        146.        195.       ]\n",
      "   ...\n",
      "   [185.        201.        224.       ]\n",
      "   [185.        201.        224.       ]\n",
      "   [185.        201.        224.       ]]]\n",
      "\n",
      "\n",
      " [[[ 37.         45.         68.       ]\n",
      "   [ 37.         45.         68.       ]\n",
      "   [ 37.         45.         68.       ]\n",
      "   ...\n",
      "   [130.        143.        177.       ]\n",
      "   [130.        143.        177.       ]\n",
      "   [130.        143.        177.       ]]\n",
      "\n",
      "  [[ 37.         45.         68.       ]\n",
      "   [ 37.         45.         68.       ]\n",
      "   [ 37.         45.         68.       ]\n",
      "   ...\n",
      "   [130.        143.        177.       ]\n",
      "   [130.        143.        177.       ]\n",
      "   [130.        143.        177.       ]]\n",
      "\n",
      "  [[ 37.         45.         68.       ]\n",
      "   [ 37.         45.         68.       ]\n",
      "   [ 37.         45.         68.       ]\n",
      "   ...\n",
      "   [130.        143.        177.       ]\n",
      "   [130.        143.        177.       ]\n",
      "   [130.        143.        177.       ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 47.         31.         68.       ]\n",
      "   [ 47.         31.         68.       ]\n",
      "   [ 47.         31.         68.       ]\n",
      "   ...\n",
      "   [ 28.         30.         53.       ]\n",
      "   [ 28.         30.         53.       ]\n",
      "   [ 28.         30.         53.       ]]\n",
      "\n",
      "  [[ 47.         31.         68.       ]\n",
      "   [ 47.         31.         68.       ]\n",
      "   [ 47.         31.         68.       ]\n",
      "   ...\n",
      "   [ 28.         30.         53.       ]\n",
      "   [ 28.         30.         53.       ]\n",
      "   [ 28.         30.         53.       ]]\n",
      "\n",
      "  [[ 47.         31.         68.       ]\n",
      "   [ 47.         31.         68.       ]\n",
      "   [ 47.         31.         68.       ]\n",
      "   ...\n",
      "   [ 28.         30.         53.       ]\n",
      "   [ 28.         30.         53.       ]\n",
      "   [ 28.         30.         53.       ]]]], shape=(32, 150, 150, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " [1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0]]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8001"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[28, 27, 28, 28, 26, 32, 27, 35, 34, 31],\n",
       " [17, 4, 3],\n",
       " [2, 14, 17, 13, 4, 17],\n",
       " [28, 28, 26],\n",
       " [2, 14, 17, 13, 4, 17],\n",
       " [17, 4, 3],\n",
       " [2, 0, 5, 4],\n",
       " [0, 19, 12],\n",
       " [28, 30],\n",
       " [7, 14, 20, 17],\n",
       " [0, 19, 12],\n",
       " [0],\n",
       " [19],\n",
       " [12],\n",
       " [18, 0, 11, 0, 3, 18],\n",
       " [2, 0, 5, 4],\n",
       " [2, 14, 17, 13, 4, 17],\n",
       " [17, 4, 3],\n",
       " [22, 14, 10],\n",
       " [4],\n",
       " [18, 0, 13, 3, 12, 8, 2, 7, 4, 18],\n",
       " [5, 14, 14, 3],\n",
       " [19, 0, 10, 4],\n",
       " [14, 20, 19],\n",
       " [1, 1],\n",
       " [2, 14, 5, 5, 4, 4],\n",
       " [1, 0, 17],\n",
       " [10, 4, 1, 0, 1, 18],\n",
       " [18, 12, 14, 14, 19, 7, 8, 4, 18],\n",
       " [2, 0, 5, 4],\n",
       " [8, 1, 12],\n",
       " [8, 1, 12],\n",
       " [13, 14, 22],\n",
       " [15, 11, 0, 24, 8, 13, 6],\n",
       " [8, 13],\n",
       " [19, 7, 4],\n",
       " [22, 8, 13, 13, 4, 17, 18],\n",
       " [2, 11, 14, 20, 3],\n",
       " [27, 27, 28, 26, 27, 26],\n",
       " [30, 28, 26, 27, 26],\n",
       " [27, 26, 28, 26, 26, 35],\n",
       " [17, 4, 18, 4, 0, 17, 2, 7],\n",
       " [31, 28, 26, 26, 35],\n",
       " [27, 28, 28, 26, 26, 34],\n",
       " [34, 28, 26, 26, 34],\n",
       " [31, 28, 26, 26, 34],\n",
       " [27, 26, 26],\n",
       " [32, 28, 26, 26, 33],\n",
       " [27, 27, 27, 28, 26, 27, 26],\n",
       " [35, 26],\n",
       " [34, 26],\n",
       " [33, 26],\n",
       " [3, 4, 4, 15, 16, 0],\n",
       " [32, 26],\n",
       " [31, 26],\n",
       " [30, 26],\n",
       " [29, 26],\n",
       " [28, 26],\n",
       " [27, 26],\n",
       " [26],\n",
       " [26],\n",
       " [27, 26],\n",
       " [28, 26],\n",
       " [8, 13, 2, 17, 4, 12, 4, 13],\n",
       " [4, 3],\n",
       " [32, 26],\n",
       " [33, 26],\n",
       " [15, 17, 14, 6, 17, 4, 18, 18],\n",
       " [8, 13],\n",
       " [15, 17, 4, 2, 8, 18, 8, 14, 13],\n",
       " [0, 13, 3],\n",
       " [2, 14, 13, 5, 8, 3, 4, 13, 2, 4]]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
